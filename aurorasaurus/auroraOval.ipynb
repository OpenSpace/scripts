{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install schedule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OVAL GEOJSON GENERATOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import schedule\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry.polygon import orient\n",
    "\n",
    "# Function to convert RGB to Hex\n",
    "def rgb_to_hex(rgb_str):\n",
    "    \"\"\"\n",
    "    Convert RGB color string in format 'rgb(r, g, b)' to HEX color code.\n",
    "\n",
    "    Parameters:\n",
    "    rgb_str (str): RGB color string in format 'rgb(r, g, b)'\n",
    "\n",
    "    Returns:\n",
    "    str: HEX color code\n",
    "    \"\"\"\n",
    "    # Extract numeric values from the string\n",
    "    rgb_values = rgb_str.split('(')[1].split(')')[0].split(',')\n",
    "    r = int(rgb_values[0].strip())\n",
    "    g = int(rgb_values[1].strip())\n",
    "    b = int(rgb_values[2].strip())\n",
    "\n",
    "\n",
    "    # Clamp RGB values within 0-255 range\n",
    "    r = max(0, min(r, 255))\n",
    "    g = max(0, min(g, 255))\n",
    "    b = max(0, min(b, 255))\n",
    "\n",
    "    # Convert RGB to HEX\n",
    "    return '#{:02x}{:02x}{:02x}'.format(r, g, b)\n",
    "\n",
    "\n",
    "\n",
    "def douglas_peucker(coords, tolerance):\n",
    "    \"\"\"Douglas-Peucker algorithm for simplifying coordinates.\"\"\"\n",
    "    from math import sqrt\n",
    "\n",
    "    def perpendicular_distance(pt, start, end):\n",
    "        # Calculate the perpendicular distance from pt to line defined by start-end\n",
    "        if start == end:\n",
    "            return sqrt((pt[0] - start[0]) ** 2 + (pt[1] - start[1]) ** 2)\n",
    "        else:\n",
    "            numerator = abs((end[1] - start[1]) * pt[0] - (end[0] - start[0]) * pt[1] + end[0] * start[1] - end[1] * start[0])\n",
    "            denominator = sqrt((end[1] - start[1]) ** 2 + (end[0] - start[0]) ** 2)\n",
    "            return numerator / denominator\n",
    "\n",
    "    def recursive_douglas_peucker(coords, tolerance, start=0, end=None):\n",
    "        if end is None:\n",
    "            end = len(coords) - 1\n",
    "\n",
    "        if end <= start + 1:\n",
    "            return [coords[start], coords[end]]\n",
    "\n",
    "        max_distance = 0\n",
    "        max_index = 0\n",
    "\n",
    "        for i in range(start + 1, end):\n",
    "            distance = perpendicular_distance(coords[i], coords[start], coords[end])\n",
    "            if distance > max_distance:\n",
    "                max_distance = distance\n",
    "                max_index = i\n",
    "\n",
    "        if max_distance >= tolerance:\n",
    "            first_part = recursive_douglas_peucker(coords, tolerance, start, max_index)\n",
    "            second_part = recursive_douglas_peucker(coords, tolerance, max_index, end)\n",
    "            return first_part[:-1] + second_part\n",
    "        else:\n",
    "            return [coords[start], coords[end]]\n",
    "\n",
    "    return recursive_douglas_peucker(coords, tolerance)\n",
    "\n",
    "\n",
    "# Function to ensure proper order, closure, and orientation of coordinates\n",
    "def process_coordinates(coords):\n",
    "    # Ensure proper order and closure\n",
    "    if coords[0] != coords[-1]:\n",
    "        coords.append(coords[0])  # Close the polygon if not closed already\n",
    "\n",
    "    # Orient the polygon\n",
    "    poly = Polygon(coords)\n",
    "    oriented_coords = list(orient(poly).exterior.coords)\n",
    "\n",
    "    oriented_coords.reverse()\n",
    "\n",
    "    # Convert coordinates to the correct format for GeoJSON\n",
    "    return [[round(x, 6), round(y, 6)] for x, y in oriented_coords]\n",
    "\n",
    "# Function to check if the polygon needs to be reversed (for poles)\n",
    "def is_polygon_reversed(coords):\n",
    "    # Determine if the polygon should be reversed based on its centroid\n",
    "    # Example logic: Check if the centroid latitude is above or below a certain threshold\n",
    "    centroid_y = sum(coord[1] for coord in coords) / len(coords)\n",
    "    if centroid_y > 0:  # Adjust this threshold as needed\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Function to simplify coordinates using Douglas-Peucker algorithm\n",
    "def simplify_coordinates(coords, tolerance=0.001):\n",
    "    simplified_coords = douglas_peucker(coords, tolerance)\n",
    "    return simplified_coords\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = 'C:/Users/alundkvi/Documents/work/scripts/oval-dataTimeTest.json'\n",
    "output_file = 'C:/Users/alundkvi/Documents/work/scripts/oval_asset_output_not_simplified/output.geojson'\n",
    "\n",
    "# Function to process each entry and generate GeoJSON-like asset\n",
    "def process_entry(entry):\n",
    "    fill_color = entry.get('fill_color', None)\n",
    "    paths = entry.get('paths', [])\n",
    "\n",
    "    # Validate input structure\n",
    "    if not fill_color or not paths:\n",
    "        return None\n",
    "\n",
    "    # Convert RGB to Hex\n",
    "    fill_color_hex = rgb_to_hex(fill_color)\n",
    "\n",
    "    optimized_paths = []\n",
    "\n",
    "    # Process each path\n",
    "    for path in paths:\n",
    "        optimized_path = []\n",
    "        \n",
    "        # Modify each coordinate in the path and optimize\n",
    "        for coord in path:\n",
    "            lat = coord.get('lat', None)\n",
    "            lng = coord.get('lng', None)\n",
    "\n",
    "            # Skip if coordinates are in the northern hemisphere\n",
    "            if lat is not None and lat > 0:\n",
    "                continue\n",
    "\n",
    "            # Swap lat and lng, subtract 400 from lng\n",
    "            if lat is not None and lng is not None:\n",
    "                optimized_path.append([\n",
    "                    lng - 360,\n",
    "                    lat\n",
    "                ])\n",
    "\n",
    "        # Simplify coordinates if there are valid points in optimized_path\n",
    "        if optimized_path:\n",
    "            simplified_coords = simplify_coordinates(optimized_path)\n",
    "            final_coords = process_coordinates(simplified_coords)\n",
    "            optimized_paths.append(final_coords)\n",
    "\n",
    "    # Construct GeoJSON-like asset structure if optimized_paths is not empty\n",
    "    if optimized_paths:\n",
    "        asset = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {\n",
    "                \"stroke\": fill_color_hex,\n",
    "                \"stroke-width\": 2,\n",
    "                \"stroke-opacity\": 1,\n",
    "                \"fill\": fill_color_hex,\n",
    "                \"fill-opacity\": 0.75\n",
    "            },\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Polygon\",\n",
    "                \"coordinates\": optimized_paths\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return asset\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to fetch data from URL\n",
    "def fetch_data_and_process(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}\")\n",
    "        return []   \n",
    "\n",
    "# Function to run the process for each 15-minute interval\n",
    "#def run_process():\n",
    "# Define the time range\n",
    "start_time = datetime(2024, 5, 10, 15, 0)\n",
    "end_time = datetime(2024, 5, 12, 0, 0)\n",
    "\n",
    "current_time = start_time\n",
    "interval_minutes = 15\n",
    "\n",
    "while current_time <= end_time:\n",
    "    formatted_time = current_time.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "    folder_name = formatted_time.replace(':', '-')\n",
    "    output_folder = f'C:/Users/alundkvi/Documents/work/scripts/oval_geojsons_south/{folder_name}/'\n",
    "\n",
    "    # Create output folder if it doesn't exist\n",
    "    try:\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "    except OSError as e:\n",
    "        print(f\"Error creating directory {output_folder}: {e}\")\n",
    "        continue\n",
    "    # Fetch data from URL\n",
    "    url = f'https://aurorasaurus.org/oval-data?end_date={current_time.strftime(\"%Y-%m-%dT%H:%M%z\")}&local_offset=0'\n",
    "    data = fetch_data_and_process(url)\n",
    "    \n",
    "    display(f\"URL: {url}\")\n",
    "\n",
    "    if data:\n",
    "        # Process each entry and generate GeoJSON-like asset\n",
    "        for index, entry in enumerate(data):\n",
    "            asset = process_entry(entry)\n",
    "            if asset:\n",
    "                # Generate output file path\n",
    "                output_file = f'{output_folder}output{index + 1}.geojson'\n",
    "\n",
    "                # Write GeoJSON-like asset to output file\n",
    "                try:\n",
    "                    with open(output_file, 'w') as out_f:\n",
    "                        json.dump(asset, out_f, indent=2)\n",
    "                    print(f'Processed entry {index + 1} saved to {output_file}')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error writing to {output_file}: {e}\")\n",
    "            else:\n",
    "                print(f'Skipped entry {index + 1} due to missing or invalid data')\n",
    "\n",
    "    # Move to the next interval\n",
    "    current_time += timedelta(minutes=interval_minutes)\n",
    "\n",
    "# Schedule the job every 15 minutes\n",
    "#schedule.every(1).minutes.do(run_process)\n",
    "\n",
    "# Run indefinitely\n",
    "#while True:\n",
    "#    schedule.run_pending()\n",
    "#    time.sleep(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OVAL ASSET GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Directory where GeoJSON files are stored\n",
    "output_directory = 'C:/Users/alundkvi/Documents/work/scripts/oval_output_only_south/'\n",
    "\n",
    "# Output directory for .asset files\n",
    "asset_output_directory = 'C:/Users/alundkvi/Documents/work/scripts/oval_only_south_assets/'\n",
    "\n",
    "# Function to generate .asset content for a folder of GeoJSON files\n",
    "def generate_asset(folder_path):\n",
    "    # Extract date and time from folder name\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    date_time_str = folder_name.replace('_', ' ')\n",
    "    date_time = datetime.strptime(date_time_str, \"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "    # Define Lua script content template\n",
    "    lua_script = f\"\"\"\n",
    "local earth = asset.require(\"scene/solarsystem/planets/earth/earth\")\n",
    "\n",
    "local geojsonPath = asset.resource(\"C:/Users/alundkvi/Documents/work/OpenSpace/user/data/assets/aurorasaurus/geojson/oval_only_south_geojsons/{folder_name}/\")\n",
    "\n",
    "\"\"\"\n",
    "# Calculate start and end times for the 15-minute interval\n",
    "    start_time_str = date_time.strftime(\"%Y %B %d %H:%M:%S\")\n",
    "    end_time = date_time + timedelta(minutes=15)\n",
    "    end_time_str = end_time.strftime(\"%Y %B %d %H:%M:%S\")\n",
    "    # Process each GeoJSON file in the folder\n",
    "    file_index = 1\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith('.geojson'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Generate Lua script for each GeoJSON file\n",
    "            lua_script += f\"\"\"\n",
    "local AuroraOval{file_index} = {{\n",
    "  Identifier = \"AuroraOval_{date_time_str}_{file_index}\",\n",
    "  File = geojsonPath .. \"{filename}\",\n",
    "  TimeFrame = {{\n",
    "    Type = \"TimeFrameInterval\",\n",
    "    Start = \"{start_time_str}\",\n",
    "    End = \"{end_time_str}\"\n",
    "  }},\n",
    "  HeightOffset = 75000,\n",
    "  Name = \"AuroraOval_{date_time_str}_{file_index}\"\n",
    "}}\n",
    "\n",
    "asset.onInitialize(function()\n",
    "\n",
    "  openspace.globebrowsing.addGeoJson(earth.Earth.Identifier, AuroraOval{file_index})\n",
    "\n",
    "end)\n",
    "\n",
    "asset.onDeinitialize(function()\n",
    "\n",
    "  openspace.globebrowsing.deleteGeoJson(earth.Earth.Identifier, AuroraOval{file_index})\n",
    "\n",
    "end)\n",
    "\n",
    "\"\"\"\n",
    "            file_index += 1\n",
    "\n",
    "            # Move to the next 15-minute interval\n",
    "            date_time = end_time\n",
    "\n",
    "    # Write Lua script to .asset file in asset_output_directory\n",
    "    asset_filename = f'{folder_name}.asset'\n",
    "    asset_filepath = os.path.join(asset_output_directory, asset_filename)\n",
    "    with open(asset_filepath, 'w') as asset_file:\n",
    "        asset_file.write(lua_script)\n",
    "\n",
    "    print(f'Generated {asset_filename} in {asset_output_directory}')\n",
    "\n",
    "# Ensure asset output directory exists\n",
    "os.makedirs(asset_output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through each folder in output_directory\n",
    "for folder_name in sorted(os.listdir(output_directory)):\n",
    "    folder_path = os.path.join(output_directory, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        generate_asset(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define start and end datetime\n",
    "start_datetime = datetime(2024, 5, 10, 15, 0, 0)\n",
    "end_datetime = datetime(2024, 5, 12, 12, 0, 0)\n",
    "\n",
    "# Define interval duration (15 minutes)\n",
    "interval = timedelta(minutes=15)\n",
    "\n",
    "# Function to generate required asset paths\n",
    "def generate_asset_requirements(start, end, interval):\n",
    "    current = start\n",
    "    while current <= end:\n",
    "        asset_path = f'asset.require(\"./oval_only_south_assets/{current.strftime(\"%Y-%m-%d_%H-%M-%S\")}\")'\n",
    "        print(asset_path)\n",
    "        current += interval\n",
    "\n",
    "# Generate asset requirements\n",
    "generate_asset_requirements(start_datetime, end_datetime, interval)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIEWLINE GEOJSON GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Function to fetch data from URL and adjust coordinates\n",
    "def fetch_northern_coordinates(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        northern_coordinates = data.get('northern', [])\n",
    "        # Adjust lng coordinates by removing 360\n",
    "        adjusted_coordinates = [(item['lng'] - 360, item['lat']) for item in northern_coordinates]\n",
    "        return adjusted_coordinates\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}\")\n",
    "        return []\n",
    "    \n",
    "    \n",
    "# Function to fetch data from URL and adjust coordinates\n",
    "def fetch_southern_coordinates(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        southern_coordinates = data.get('southern', [])\n",
    "        # Adjust lng coordinates by removing 360\n",
    "        adjusted_coordinates = [(item['lng'] - 360, item['lat']) for item in southern_coordinates]\n",
    "        return adjusted_coordinates\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}\")\n",
    "        return []\n",
    "\n",
    "# Function to create LineString GeoJSON and save to file\n",
    "def create_geojson_file(coordinates, output_path):\n",
    "    if not os.path.exists(os.path.dirname(output_path)):\n",
    "        os.makedirs(os.path.dirname(output_path))\n",
    "        \n",
    "    feature_collection = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": []\n",
    "    }\n",
    "\n",
    "    line_feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": {\n",
    "            \"name\": \"Aurora viewline\",\n",
    "            \"stroke\": \"#FF5733\"\n",
    "        },\n",
    "        \"geometry\": {\n",
    "            \"type\": \"LineString\",\n",
    "            \"coordinates\": coordinates\n",
    "        }\n",
    "    }\n",
    "\n",
    "    feature_collection[\"features\"].append(line_feature)\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(feature_collection, f, indent=4)\n",
    "\n",
    "# Define output directory\n",
    "output_directory = \"C:/Users/alundkvi/Documents/work/scripts/southern_viewline_asset_output/\"\n",
    "\n",
    "# Define start and end datetime\n",
    "start_datetime = datetime(2024, 5, 10, 15, 0, 0)\n",
    "end_datetime = datetime(2024, 5, 12, 0, 0, 0)\n",
    "interval = timedelta(minutes=15)\n",
    "\n",
    "# Iterate through each 15-minute interval\n",
    "current_datetime = start_datetime\n",
    "while current_datetime <= end_datetime:\n",
    "    # Construct URL for the current interval\n",
    "    formatted_datetime = current_datetime.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "    url = f\"https://aurorasaurus.org/view-lines?end_date={formatted_datetime}&format=json&local_offset=0\"\n",
    "\n",
    "    # Fetch northern coordinates from URL\n",
    "    #northern_coordinates = fetch_northern_coordinates(url)\n",
    "\n",
    "    # Fetch southern coordinates from URL\n",
    "    southern_coordinates = fetch_southern_coordinates(url)\n",
    "\n",
    "    # Create output filename based on datetime\n",
    "    output_filename = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\") + \".geojson\"\n",
    "    output_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "    # Create GeoJSON file with northern coordinates in the specified format\n",
    "    #create_geojson_file(northern_coordinates, output_path)\n",
    "    \n",
    "    # Create GeoJSON file with southern coordinates in the specified format\n",
    "    create_geojson_file(southern_coordinates, output_path)\n",
    "\n",
    "    # Move to the next interval\n",
    "    current_datetime += interval\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIEWLINE ASSET GENERATOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Directory where GeoJSON files are stored\n",
    "output_directory = 'C:/Users/alundkvi/Documents/work/scripts/southern_viewline_asset_output/'\n",
    "\n",
    "# Output directory for .asset files\n",
    "asset_output_directory = 'C:/Users/alundkvi/Documents/work/scripts/southern_viewline_asset/'\n",
    "\n",
    "# Function to generate .asset content for a folder of GeoJSON files\n",
    "def generate_asset(folder_path):\n",
    "    # Define Lua script content template\n",
    "    lua_script = f\"\"\"\n",
    "local earth = asset.require(\"scene/solarsystem/planets/earth/earth\")\n",
    "\n",
    "local geojsonPath = asset.resource(\"geojson/southern_viewline_geojsons/\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Process each GeoJSON file in the folder\n",
    "    file_index = 1\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith('.geojson'):\n",
    "             # Extract date and time from file name\n",
    "            date_time_str = filename.replace('_', ' ')\n",
    "            date_time_str = date_time_str.replace('.geojson', '')\n",
    "            date_time = datetime.strptime(date_time_str, \"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "        # Calculate start and end times for the 15-minute interval\n",
    "            start_time_str = date_time.strftime(\"%Y %B %d %H:%M:%S\")\n",
    "            end_time = date_time + timedelta(minutes=15)\n",
    "            end_time_str = end_time.strftime(\"%Y %B %d %H:%M:%S\")\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Generate Lua script for each GeoJSON file\n",
    "            lua_script += f\"\"\"\n",
    "local southern_viewline_{file_index} = {{\n",
    "  Identifier = \"southern_viewline_{date_time_str}_{file_index}\",\n",
    "  File = geojsonPath .. \"{filename}\",\n",
    "  TimeFrame = {{\n",
    "    Type = \"TimeFrameInterval\",\n",
    "    Start = \"{start_time_str}\",\n",
    "    End = \"{end_time_str}\"\n",
    "  }},\n",
    "  HeightOffset = 75000,\n",
    "  Name = \"southern_viewline_{date_time_str}_{file_index}\"\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "            file_index += 1\n",
    "\n",
    "            # Move to the next 15-minute interval\n",
    "            date_time = end_time\n",
    "\n",
    "\n",
    "    lua_script += f\"\"\"\n",
    "asset.onInitialize(function()\n",
    "\"\"\"\n",
    "\n",
    "    for i in range(1, file_index):\n",
    "      lua_script += f\"\"\"openspace.globebrowsing.addGeoJson(earth.Earth.Identifier, southern_viewline_{i})\n",
    "\"\"\"\n",
    "    lua_script += f\"\"\"\n",
    "end)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    lua_script += f\"\"\"\n",
    "asset.onDeinitialize(function()\n",
    "\"\"\"\n",
    "    for i in range(1, file_index):\n",
    "      lua_script += f\"\"\"openspace.globebrowsing.deleteGeoJson(earth.Earth.Identifier, southern_viewline_{i})\n",
    "\"\"\"\n",
    "    lua_script += f\"\"\"\n",
    "end)\n",
    "\n",
    "\"\"\"\n",
    "    # Write Lua script to .asset file in asset_output_directory\n",
    "    asset_filename = 'southernViewline.asset'\n",
    "    asset_filepath = os.path.join(asset_output_directory, asset_filename)\n",
    "    with open(asset_filepath, 'w') as asset_file:\n",
    "        asset_file.write(lua_script)\n",
    "\n",
    "    print(f'Generated {asset_filename} in {asset_output_directory}')\n",
    "\n",
    "# Ensure asset output directory exists\n",
    "os.makedirs(asset_output_directory, exist_ok=True)\n",
    "\n",
    "generate_asset(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install GDAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Fiona\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.21.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAYER OVAL THIS IS THE ACTUAL ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Root directory containing folders with GeoJSON files\n",
    "root_dir = 'C:/Users/alundkvi/Documents/work/scripts/oval_geojsons_south/temp/'\n",
    "\n",
    "# Function to determine the shift needed for longitudes to fit within -180 to 180\n",
    "def calculate_shift_amounts(coords):\n",
    "    longitudes = coords[:, 0]\n",
    "    shift = 0\n",
    "    plus = True\n",
    "    abs_max = abs(np.max(longitudes))\n",
    "    abs_min = abs(np.min(longitudes))\n",
    "\n",
    "    if abs_max > abs_min and np.max(longitudes) > 180:\n",
    "        shift = np.max(longitudes) - 180\n",
    "        plus = False\n",
    "    elif abs_max < abs_min and np.min(longitudes) < -180:\n",
    "        shift = -180 - np.min(coords[:, 0])\n",
    "        plus = True\n",
    "\n",
    "    return shift, plus\n",
    "\n",
    "def shift_image(image_path, degrees, output_path):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert(\"RGBA\")  # Ensure the image is in RGBA mode to handle transparency\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Calculate how many pixels to shift\n",
    "    pixels_per_degree = width / 360\n",
    "    shift_pixels = int(degrees * pixels_per_degree)\n",
    "\n",
    "    # Create a new image with transparent background\n",
    "    new_image = Image.new('RGBA', (width, height), (0, 0, 0, 0))\n",
    "\n",
    "    # Split the image into two parts, considering transparency\n",
    "    right_part = image.crop((width - shift_pixels, 0, width, height))\n",
    "    left_part = image.crop((0, 0, width - shift_pixels, height))\n",
    "\n",
    "    # Paste the shifted parts onto the new image\n",
    "    new_image.paste(right_part, (0, 0), right_part)  # Use the image itself as a mask to preserve transparency\n",
    "    new_image.paste(left_part, (shift_pixels, 0), left_part)  # Use the image itself as a mask to preserve transparency\n",
    "\n",
    "    # Save the result\n",
    "    new_image.save(output_path)\n",
    "    \n",
    "def shift_image_left(image_path, degrees, output_path):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert(\"RGBA\")  # Ensure the image is in RGBA mode to handle transparency\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Calculate how many pixels to shift\n",
    "    pixels_per_degree = width / 360\n",
    "    shift_pixels = int(degrees * pixels_per_degree)\n",
    "\n",
    "    # Create a new image with transparent background\n",
    "    new_image = Image.new('RGBA', (width, height), (0, 0, 0, 0))\n",
    "\n",
    "    # Split the image into two parts, considering transparency\n",
    "    left_part = image.crop((0, 0, shift_pixels, height))\n",
    "    right_part = image.crop((shift_pixels, 0, width, height))\n",
    "\n",
    "    # Paste the shifted parts onto the new image\n",
    "    new_image.paste(left_part, (width - shift_pixels, 0), left_part)  # Paste left part at the end to wrap around\n",
    "    new_image.paste(right_part, (0, 0), right_part)  # Paste right part in its original position\n",
    "\n",
    "    # Save the result\n",
    "    new_image.save(output_path)\n",
    "\n",
    "# Function to adjust coordinates based on shift amounts\n",
    "def adjust_longitudes(coords, shift, plus):\n",
    "    if plus == False:\n",
    "        coords[:, 0] -= shift\n",
    "    else:\n",
    "        coords[:, 0] += shift\n",
    "    return coords\n",
    "\n",
    "# Iterate over all subdirectories and their files\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "    geojson_files = [f for f in filenames if f.endswith('.geojson')]\n",
    "\n",
    "    if not geojson_files:\n",
    "        continue\n",
    "\n",
    "    # Process each GeoJSON file to determine the maximum and minimum longitudes\n",
    "    all_coords = []\n",
    "    for filename in geojson_files:\n",
    "        geojson_file = os.path.join(dirpath, filename)\n",
    "        gdf = gpd.read_file(geojson_file)\n",
    "        polygon_coords = np.array(gdf['geometry'][0].exterior.coords.xy).T\n",
    "        all_coords.append(polygon_coords)\n",
    "\n",
    "    # Flatten list of coordinates\n",
    "    all_coords = np.vstack(all_coords)\n",
    "\n",
    "    # Calculate the shift amounts\n",
    "    shift, plus = calculate_shift_amounts(all_coords)\n",
    "\n",
    "    print(dirpath)\n",
    "    print(shift)\n",
    "    #print(\" \")\n",
    "\n",
    "    # Apply the shift to each file\n",
    "    for filename in geojson_files:\n",
    "        geojson_file = os.path.join(dirpath, filename)\n",
    "        gdf = gpd.read_file(geojson_file)\n",
    "        polygon_coords = np.array(gdf['geometry'][0].exterior.coords.xy).T\n",
    "\n",
    "        # Adjust longitudes\n",
    "        adjusted_coords = adjust_longitudes(polygon_coords, shift, plus)\n",
    "\n",
    "        # Extract fill color from GeoJSON properties\n",
    "        fill_color = gdf['fill'][0]\n",
    "\n",
    "        # Create a figure and axis with specific dimensions\n",
    "        fig, ax = plt.subplots(figsize=(72, 36))\n",
    "\n",
    "        # Create a polygon patch for the adjusted coordinates\n",
    "        if len(adjusted_coords) > 0:\n",
    "            polygon_patch = Polygon(adjusted_coords, closed=True, edgecolor=fill_color, facecolor=fill_color, alpha=1)\n",
    "            ax.add_patch(polygon_patch)\n",
    "\n",
    "        # Set axis limits and aspect ratio\n",
    "        ax.set_xlim(-180, 180)\n",
    "        ax.set_ylim(-90, 90)\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        # Remove axes\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Output image file path\n",
    "        output_file = os.path.splitext(filename)[0] + '.png'\n",
    "        output_path = os.path.join(dirpath, output_file)\n",
    "\n",
    "        # Save the image\n",
    "        plt.savefig(output_path, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        plt.close()  # Close the current figure to free up memory\n",
    "\n",
    "        shift_image_left(output_path, shift, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
