{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOCAL MAY 2024!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import requests  # Import requests module for HTTP requests\n",
    "from urllib.parse import unquote\n",
    "\n",
    "# Configuration\n",
    "csv_file_path = 'C:/Users/alundkvi/Documents/work/data/auroraData/Filter_web_observation_may2024.csv'\n",
    "output_file_base = 'C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/mayRenderbinMode/'\n",
    "image_base_path = 'C:/Users/alundkvi/Documents/work/data/auroraData/mayImagesCompressed/'\n",
    "user_assets_path = '${USER_ASSETS}/aurorasaurus/icons/newIcons2/'\n",
    "user_assets_path_shapes = '${USER_ASSETS}/aurorasaurus/icons/newIcons3/'\n",
    "not_seen_aurora_icon_path = '${USER_ASSETS}/aurorasaurus/icons/grayIcon.png'\n",
    "default_icon_path = 'green2.png'\n",
    "offset_step = 0.2  # Small offset step for adjusting positions\n",
    "distance_threshold = 0.2\n",
    "max_variables_per_file = 190  # Maximum number of local variables per file\n",
    "\n",
    "# Define image paths based on colors\n",
    "color_to_image_path = {\n",
    "    'green': 'green2.png',\n",
    "    'red': 'red2.png',\n",
    "    'white': 'white2.png',\n",
    "    'pink': 'pink2.png',\n",
    "    'green,red': 'greenRed2.png',\n",
    "    'green,white': 'greenWhite2.png',\n",
    "    'green,pink': 'greenPink2.png',\n",
    "    'green,red,white': 'greenRedWhite2.png',\n",
    "    'green,pink,red': 'greenRedPink2.png',\n",
    "    'green,pink,white': 'greenWhitePink2.png',\n",
    "    'green,pink,red,white': 'greenRedWhitePink2.png',\n",
    "    'red,white': 'redWhite2.png',\n",
    "    'pink,red': 'redPink2.png',\n",
    "    'pink,red,white': 'redWhitePink2.png',\n",
    "    'pink,white': 'whitePink2.png'\n",
    "}\n",
    "\n",
    "\"\"\" color_to_image_path_camera = {\n",
    "    'green': 'greenCamera.png',\n",
    "    'red': 'redCamera.png',\n",
    "    'white': 'whiteCamera.png',\n",
    "    'pink': 'pinkCamera.png',\n",
    "    'green,red': 'greenRedCamera.png',\n",
    "    'green,white': 'greenWhiteCamera.png',\n",
    "    'green,pink': 'greenPinkCamera.png',\n",
    "    'green,red,white': 'greenRedWhiteCamera.png',\n",
    "    'green,pink,red': 'greenRedPinkCamera.png',\n",
    "    'green,pink,white': 'greenWhitePinkCamera.png',\n",
    "    'green,pink,red,white': 'greenRedWhitePinkCamera.png',\n",
    "    'red,white': 'redWhiteCamera.png',\n",
    "    'pink,red': 'redPinkCamera.png',\n",
    "    'pink,red,white': 'redWhitePinkCamera.png',\n",
    "    'pink,white': 'whitePinkCamera.png'\n",
    "} \"\"\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Ensure all_colors is a string and handle missing values\n",
    "df['all_colors'] = df['all_colors'].fillna('').astype(str)\n",
    "\n",
    "# Lua Template\n",
    "lua_template = '''local {var_name} = {{\n",
    "  Identifier = \"{identifier}\",\n",
    "  Parent = earth.Earth.Identifier,\n",
    "  TimeFrame = {{\n",
    "    Type = \"TimeFrameInterval\",\n",
    "    Start = \"{start_time}\",\n",
    "    End = \"{end_time}\"\n",
    "  }},\n",
    "  Transform = {{\n",
    "    Translation = {{\n",
    "      Type = \"GlobeTranslation\",\n",
    "      Globe = earth.Earth.Identifier,\n",
    "      Latitude = {latitude},\n",
    "      Longitude = {longitude},\n",
    "      Altitude = {altitude},\n",
    "      UseHeightmap = false\n",
    "    }}\n",
    "  }},\n",
    "  Renderable = {{\n",
    "    Type = \"{renderable_type}\",\n",
    "    {renderable_details}\n",
    "  }},\n",
    "  GUI = {{\n",
    "    Path = \"/{gui_path}\",\n",
    "    Name = \"{gui_name}\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "'''\n",
    "\n",
    "# Function to write Lua script to file (modified for appending)\n",
    "def write_lua_script(filename, lua_script, aurora_identifiers):\n",
    "    earth_asset_code = 'local earth = asset.require(\"scene/solarsystem/planets/earth/earth\")\\n\\n'\n",
    "\n",
    "    earth_asset = \"scene/solarsystem/planets/earth/earth\"\n",
    "    earth_asset_code = f'local earth = asset.require(\"{earth_asset}\")\\n\\n'\n",
    "\n",
    "    asset_management_code = \"\\n\\nasset.onInitialize(function()\\n\"\n",
    "    asset_management_code += ''.join([f\"  openspace.addSceneGraphNode({identifier})\\n\" for identifier in aurora_identifiers])\n",
    "    asset_management_code += \"end)\\n\\n\"\n",
    "\n",
    "    asset_management_code += \"asset.onDeinitialize(function()\\n\"\n",
    "    asset_management_code += ''.join([f\"  openspace.removeSceneGraphNode({identifier})\\n\" for identifier in aurora_identifiers])\n",
    "    asset_management_code += \"end)\\n\\n\"\n",
    "\n",
    "    asset_management_code += ''.join([f\"asset.export({identifier})\\n\" for identifier in aurora_identifiers])\n",
    "\n",
    "    final_lua_script = earth_asset_code + '\\n'.join(lua_script) + asset_management_code\n",
    "\n",
    "    # Append to file using 'a' mode to ensure appending\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(final_lua_script)\n",
    "\n",
    "    print(f\"Lua script generated and saved to {filename}\")\n",
    "\n",
    "# Function to generate Lua code\n",
    "def generate_lua_code(var_name, identifier, start_time, end_time, latitude, longitude, altitude, renderable_type, renderable_details, gui_path, gui_name):\n",
    "    return lua_template.format(\n",
    "        var_name=var_name,\n",
    "        identifier=identifier,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        latitude=latitude,\n",
    "        longitude=longitude,\n",
    "        altitude = altitude,\n",
    "        renderable_type=renderable_type,\n",
    "        renderable_details=renderable_details,\n",
    "        gui_path=gui_path,\n",
    "        gui_name=gui_name\n",
    "    )\n",
    "\n",
    "# Haversine formula to calculate the distance between two points\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Earth radius in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Function to adjust positions if they are within the distance threshold\n",
    "def adjust_position(existing_positions, latitude, longitude):\n",
    "    for (lat, lon) in existing_positions:\n",
    "        if haversine(lat, lon, latitude, longitude) < distance_threshold:\n",
    "            latitude += offset_step\n",
    "            longitude += offset_step\n",
    "    return latitude, longitude\n",
    "\n",
    "# Initialize lists and counters\n",
    "start_date = pd.Timestamp('2024-05-9').tz_localize(None)\n",
    "end_date = pd.Timestamp('2024-05-13').tz_localize(None)\n",
    "chunk_counter = 0\n",
    "lua_scripts = []\n",
    "aurora_identifiers = []\n",
    "\n",
    "# Loop through DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "  \n",
    "  time_start = pd.Timestamp(row['time_start']).tz_localize(None)\n",
    "  if start_date <= time_start <= end_date:\n",
    "      longitude, latitude = map(float, re.findall(r'[-]?\\d+\\.\\d+', row['location']))\n",
    "\n",
    "      # Adjust position if overlapping\n",
    "      #latitude, longitude = adjust_position(existing_positions, latitude, longitude)\n",
    "      #existing_positions.append((latitude, longitude))\n",
    "\n",
    "      start_time = time_start.strftime('%Y %b %d %H:%M:%S')\n",
    "      end_time = pd.to_datetime(row['time_end']).strftime('%Y %b %d %H:%M:%S')\n",
    "      if not row['see_aurora']:\n",
    "          var_name = f\"notSeenAuroraIcon{index+1}\"\n",
    "          identifier = var_name\n",
    "          icon_path = not_seen_aurora_icon_path\n",
    "          altitude = 95000\n",
    "          gui_name = f\"Aurora not seen {index+1}\"\n",
    "          renderable_details = f'''Size = 75000,\n",
    "  Origin = \"Center\",\n",
    "  Billboard = true,\n",
    "  Texture = \"{icon_path}\",\n",
    "  Opacity = 1.0,\n",
    "  Enabled = true,\n",
    "  RenderBinMode = \"PostDeferredTransparent\"'''\n",
    "          renderable_type = \"RenderablePlaneImageLocal\"\n",
    "      else:\n",
    "          colors = [c.strip().lower() for c in row['all_colors'].split(',')]\n",
    "\n",
    "          # Join sorted colors to handle combinations correctly\n",
    "          color_key = ','.join(sorted(colors))\n",
    "\n",
    "          if not pd.isna(row['image']) and row['image'] != 'NA':\n",
    "              var_name = f\"shapeAurora{''.join([c.capitalize() for c in colors])}{index+1}\"\n",
    "              identifier = var_name\n",
    "              image_name = f\"image_{index+1}.{'jpg' if os.path.exists(os.path.join(image_base_path, f'image_{index+1}.jpg')) else 'png'}\"\n",
    "              icon_path = user_assets_path + color_to_image_path.get(color_key, default_icon_path)\n",
    "              altitude = 120000\n",
    "              gui_name = f\"Aurora Image {index+1}\"\n",
    "              renderable_details = f'''Renderable1 = {{\n",
    "        Type = \"RenderablePlaneImageLocal\",\n",
    "        Size = 75000,\n",
    "        Origin = \"Center\",\n",
    "        Billboard = true,\n",
    "        Texture = \"{image_base_path}{image_name}\",\n",
    "        Opacity = 1,\n",
    "        Enabled = true,\n",
    "        RenderBinMode = \"PostDeferredTransparent\"\n",
    "      }},\n",
    "      Renderable2 = {{\n",
    "        Type = \"RenderablePlaneImageLocal\",\n",
    "        Size = 75000,\n",
    "        Origin = \"Center\",\n",
    "        Billboard = true,\n",
    "        Texture = \"{icon_path}\",\n",
    "        Opacity = 1,\n",
    "        Enabled = true,\n",
    "        RenderBinMode = \"PostDeferredTransparent\"\n",
    "      }},\n",
    "      DistanceThreshold = 1000000'''\n",
    "              renderable_type = \"RenderableSwitch\"\n",
    "          else:\n",
    "              var_name = f\"shapeIcon{''.join([c.capitalize() for c in colors])}{index+1}\"\n",
    "              identifier = var_name\n",
    "              icon_path = user_assets_path + color_to_image_path.get(color_key, default_icon_path)\n",
    "              gui_name = f\"Time Frame Icon {' '.join([c.capitalize() for c in colors])} {index+1}\"\n",
    "              altitude = 100000\n",
    "              renderable_details = f'''Size = 75000,\n",
    "      Origin = \"Center\",\n",
    "      Billboard = true,\n",
    "      Texture = \"{icon_path}\",\n",
    "      Opacity = 1.0,\n",
    "      Enabled = true,\n",
    "      RenderBinMode = \"PostDeferredTransparent\"'''\n",
    "              renderable_type = \"RenderablePlaneImageLocal\"\n",
    "\n",
    "      # Generate Lua code and append to lua_scripts\n",
    "      lua_code = generate_lua_code(var_name, identifier, start_time, end_time, latitude, longitude, altitude, renderable_type, renderable_details.strip(), \"Aurorasaurus/IconsWithoutImage\" if row['image'] == 'NA' else \"Aurorasaurus\", gui_name)\n",
    "      lua_scripts.append(lua_code)\n",
    "      aurora_identifiers.append(identifier)\n",
    "\n",
    "      # Check if we need to write lua_scripts to a new file\n",
    "      if len(lua_scripts) >= max_variables_per_file:\n",
    "          chunk_counter += 1\n",
    "          filename = f\"{output_file_base}{chunk_counter}.asset\"\n",
    "          write_lua_script(filename, lua_scripts, aurora_identifiers)\n",
    "          # Reset lua_scripts and aurora_identifiers for the next chunk\n",
    "          lua_scripts = []\n",
    "          aurora_identifiers = []\n",
    "\n",
    "# Write remaining lua_scripts to file if any\n",
    "if lua_scripts:\n",
    "    chunk_counter += 1\n",
    "    filename = f\"{output_file_base}{chunk_counter}.asset\"\n",
    "    write_lua_script(filename, lua_scripts, aurora_identifiers)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "was ICON SWITCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import requests  # Import requests module for HTTP requests\n",
    "from urllib.parse import unquote\n",
    "\n",
    "# Configuration\n",
    "csv_file_path = 'C:/Users/alundkvi/Documents/work/data/auroraData/Filter_web_observation_may2024.csv'\n",
    "output_file_base = 'C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024Final/'\n",
    "image_base_path = 'C:/Users/alundkvi/Documents/work/data/auroraData/mayImagesCompressed/'\n",
    "user_assets_path = '${USER_ASSETS}/aurorasaurus/icons/newIcons2/'\n",
    "user_assets_path_shapes = '${USER_ASSETS}/aurorasaurus/icons/newIcons3/'\n",
    "not_seen_aurora_icon_path = '${USER_ASSETS}/aurorasaurus/icons/grayIcon.png'\n",
    "default_icon_path = 'green2.png'\n",
    "offset_step = 0.2  # Small offset step for adjusting positions\n",
    "distance_threshold = 0.2\n",
    "max_variables_per_file = 190  # Maximum number of local variables per file\n",
    "\n",
    "# Define image paths based on colors\n",
    "color_to_image_path = {\n",
    "    'green': 'green2.png',\n",
    "    'red': 'red2.png',\n",
    "    'white': 'white2.png',\n",
    "    'pink': 'pink2.png',\n",
    "    'green,red': 'greenRed2.png',\n",
    "    'green,white': 'greenWhite2.png',\n",
    "    'green,pink': 'greenPink2.png',\n",
    "    'green,red,white': 'greenRedWhite2.png',\n",
    "    'green,pink,red': 'greenRedPink2.png',\n",
    "    'green,pink,white': 'greenWhitePink2.png',\n",
    "    'green,pink,red,white': 'greenRedWhitePink2.png',\n",
    "    'red,white': 'redWhite2.png',\n",
    "    'pink,red': 'redPink2.png',\n",
    "    'pink,red,white': 'redWhitePink2.png',\n",
    "    'pink,white': 'whitePink2.png'\n",
    "}\n",
    "\n",
    "color_to_image_path_camera = {\n",
    "    'green': 'greenCamera.png',\n",
    "    'red': 'redCamera.png',\n",
    "    'white': 'whiteCamera.png',\n",
    "    'pink': 'pinkCamera.png',\n",
    "    'green,red': 'greenRedCamera.png',\n",
    "    'green,white': 'greenWhiteCamera.png',\n",
    "    'green,pink': 'greenPinkCamera.png',\n",
    "    'green,red,white': 'greenRedWhiteCamera.png',\n",
    "    'green,pink,red': 'greenRedPinkCamera.png',\n",
    "    'green,pink,white': 'greenWhitePinkCamera.png',\n",
    "    'green,pink,red,white': 'greenRedWhitePinkCamera.png',\n",
    "    'red,white': 'redWhiteCamera.png',\n",
    "    'pink,red': 'redPinkCamera.png',\n",
    "    'pink,red,white': 'redWhitePinkCamera.png',\n",
    "    'pink,white': 'whitePinkCamera.png'\n",
    "} \n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Ensure all_colors is a string and handle missing values\n",
    "df['all_colors'] = df['all_colors'].fillna('').astype(str)\n",
    "\n",
    "# Lua Template\n",
    "lua_template = '''local {var_name} = {{\n",
    "  Identifier = \"{identifier}\",\n",
    "  Parent = earth.Earth.Identifier,\n",
    "  TimeFrame = {{\n",
    "    Type = \"TimeFrameInterval\",\n",
    "    Start = \"{start_time}\",\n",
    "    End = \"{end_time}\"\n",
    "  }},\n",
    "  Transform = {{\n",
    "    Translation = {{\n",
    "      Type = \"GlobeTranslation\",\n",
    "      Globe = earth.Earth.Identifier,\n",
    "      Latitude = {latitude},\n",
    "      Longitude = {longitude},\n",
    "      Altitude = {altitude},\n",
    "      UseHeightmap = false\n",
    "    }}\n",
    "  }},\n",
    "  Renderable = {{\n",
    "    Type = \"{renderable_type}\",\n",
    "    {renderable_details}\n",
    "  }},\n",
    "  GUI = {{\n",
    "    Path = \"/{gui_path}\",\n",
    "    Name = \"{gui_name}\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "'''\n",
    "\n",
    "# Function to write Lua script to file (modified for appending)\n",
    "def write_lua_script(filename, lua_script, aurora_identifiers):\n",
    "    earth_asset_code = 'local earth = asset.require(\"scene/solarsystem/planets/earth/earth\")\\n\\n'\n",
    "\n",
    "    earth_asset = \"scene/solarsystem/planets/earth/earth\"\n",
    "    earth_asset_code = f'local earth = asset.require(\"{earth_asset}\")\\n\\n'\n",
    "\n",
    "    asset_management_code = \"\\n\\nasset.onInitialize(function()\\n\"\n",
    "    asset_management_code += ''.join([f\"  openspace.addSceneGraphNode({identifier})\\n\" for identifier in aurora_identifiers])\n",
    "    asset_management_code += \"end)\\n\\n\"\n",
    "\n",
    "    asset_management_code += \"asset.onDeinitialize(function()\\n\"\n",
    "    asset_management_code += ''.join([f\"  openspace.removeSceneGraphNode({identifier})\\n\" for identifier in aurora_identifiers])\n",
    "    asset_management_code += \"end)\\n\\n\"\n",
    "\n",
    "    asset_management_code += ''.join([f\"asset.export({identifier})\\n\" for identifier in aurora_identifiers])\n",
    "\n",
    "    final_lua_script = earth_asset_code + '\\n'.join(lua_script) + asset_management_code\n",
    "\n",
    "    # Append to file using 'a' mode to ensure appending\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(final_lua_script)\n",
    "\n",
    "    print(f\"Lua script generated and saved to {filename}\")\n",
    "\n",
    "# Function to generate Lua code\n",
    "def generate_lua_code(var_name, identifier, start_time, end_time, latitude, longitude, altitude, renderable_type, renderable_details, gui_path, gui_name):\n",
    "    return lua_template.format(\n",
    "        var_name=var_name,\n",
    "        identifier=identifier,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        latitude=latitude,\n",
    "        longitude=longitude,\n",
    "        altitude = altitude,\n",
    "        renderable_type=renderable_type,\n",
    "        renderable_details=renderable_details,\n",
    "        gui_path=gui_path,\n",
    "        gui_name=gui_name\n",
    "    )\n",
    "\n",
    "# Haversine formula to calculate the distance between two points\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Earth radius in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Function to adjust positions if they are within the distance threshold\n",
    "def adjust_position(existing_positions, latitude, longitude):\n",
    "    for (lat, lon) in existing_positions:\n",
    "        if haversine(lat, lon, latitude, longitude) < distance_threshold:\n",
    "            latitude += offset_step\n",
    "            longitude += offset_step\n",
    "    return latitude, longitude\n",
    "\n",
    "# Initialize lists and counters\n",
    "start_date = pd.Timestamp('2024-05-9').tz_localize(None)\n",
    "end_date = pd.Timestamp('2024-05-13').tz_localize(None)\n",
    "chunk_counter = 0\n",
    "lua_scripts = []\n",
    "aurora_identifiers = []\n",
    "\n",
    "# Loop through DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "  \n",
    "  time_start = pd.Timestamp(row['time_start']).tz_localize(None)\n",
    "  if start_date <= time_start <= end_date:\n",
    "      longitude, latitude = map(float, re.findall(r'[-]?\\d+\\.\\d+', row['location']))\n",
    "\n",
    "      # Adjust position if overlapping\n",
    "      #latitude, longitude = adjust_position(existing_positions, latitude, longitude)\n",
    "      #existing_positions.append((latitude, longitude))\n",
    "\n",
    "      start_time = time_start.strftime('%Y %b %d %H:%M:%S')\n",
    "      end_time = pd.to_datetime(row['time_end']).strftime('%Y %b %d %H:%M:%S')\n",
    "      if not row['see_aurora']:\n",
    "          #continue\n",
    "          var_name = f\"notSeenAuroraIcon{index+1}\"\n",
    "          identifier = var_name\n",
    "          icon_path = not_seen_aurora_icon_path\n",
    "          altitude = 95000\n",
    "          gui_name = f\"Aurora not seen {index+1}\"\n",
    "          renderable_details = f'''Size = 75000,\n",
    "  Origin = \"Center\",\n",
    "  Billboard = true,\n",
    "  Texture = \"{icon_path}\",\n",
    "  Opacity = 1.0,\n",
    "  Enabled = true'''\n",
    "          renderable_type = \"RenderablePlaneImageLocal\"\n",
    "      else:\n",
    "          colors = [c.strip().lower() for c in row['all_colors'].split(',')]\n",
    "\n",
    "          # Join sorted colors to handle combinations correctly\n",
    "          color_key = ','.join(sorted(colors))\n",
    "\n",
    "          if not pd.isna(row['image']) and row['image'] != 'NA':\n",
    "              var_name = f\"Aurora{''.join([c.capitalize() for c in colors])}{index+1}\"\n",
    "              identifier = var_name\n",
    "              image_name = f\"image_{index+1}.{'jpg' if os.path.exists(os.path.join(image_base_path, f'image_{index+1}.jpg')) else 'png'}\"\n",
    "              icon_path = user_assets_path + color_to_image_path_camera.get(color_key, default_icon_path)\n",
    "              altitude = 120000\n",
    "              gui_name = f\"Aurora Image {index+1}\"\n",
    "              renderable_details = f'''Renderable1 = {{\n",
    "        Type = \"RenderablePlaneImageLocal\",\n",
    "        Size = 75000,\n",
    "        Origin = \"Center\",\n",
    "        Billboard = true,\n",
    "        Texture = \"{image_base_path}{image_name}\",\n",
    "        Opacity = 1,\n",
    "        Enabled = true\n",
    "      }},\n",
    "      Renderable2 = {{\n",
    "        Type = \"RenderablePlaneImageLocal\",\n",
    "        Size = 75000,\n",
    "        Origin = \"Center\",\n",
    "        Billboard = true,\n",
    "        Texture = \"{icon_path}\",\n",
    "        Opacity = 1,\n",
    "        Enabled = true\n",
    "      }},\n",
    "      DistanceThreshold = 1000000'''\n",
    "              renderable_type = \"RenderableSwitch\"\n",
    "          else:\n",
    "              var_name = f\"icon{''.join([c.capitalize() for c in colors])}{index+1}\"\n",
    "              identifier = var_name\n",
    "              icon_path = user_assets_path + color_to_image_path.get(color_key, default_icon_path)\n",
    "              #icon_path2 = user_assets_path_shapes + color_to_image_path.get(color_key, default_icon_path)\n",
    "              gui_name = f\"Time Frame Icon {' '.join([c.capitalize() for c in colors])} {index+1}\"\n",
    "              altitude = 100000\n",
    "              renderable_details = f'''Size = 75000,\n",
    "      Origin = \"Center\",\n",
    "      Billboard = true,\n",
    "      Texture = \"{icon_path}\",\n",
    "      Opacity = 1.0,\n",
    "      Enabled = true'''\n",
    "              renderable_type = \"RenderablePlaneImageLocal\"\n",
    "\n",
    "      # Generate Lua code and append to lua_scripts\n",
    "      lua_code = generate_lua_code(var_name, identifier, start_time, end_time, latitude, longitude, altitude, renderable_type, renderable_details.strip(), \"Aurorasaurus/IconsWithoutImage\" if row['image'] == 'NA' else \"Aurorasaurus\", gui_name)\n",
    "      lua_scripts.append(lua_code)\n",
    "      aurora_identifiers.append(identifier)\n",
    "\n",
    "      # Check if we need to write lua_scripts to a new file\n",
    "      if len(lua_scripts) >= max_variables_per_file:\n",
    "          chunk_counter += 1\n",
    "          filename = f\"{output_file_base}{chunk_counter}.asset\"\n",
    "          write_lua_script(filename, lua_scripts, aurora_identifiers)\n",
    "          # Reset lua_scripts and aurora_identifiers for the next chunk\n",
    "          lua_scripts = []\n",
    "          aurora_identifiers = []\n",
    "\n",
    "# Write remaining lua_scripts to file if any\n",
    "if lua_scripts:\n",
    "    chunk_counter += 1\n",
    "    filename = f\"{output_file_base}{chunk_counter}.asset\"\n",
    "    write_lua_script(filename, lua_scripts, aurora_identifiers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.8/11.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.6 MB 32.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 21.4 MB/s eta 0:00:00\n",
      "Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 10.2/15.9 MB 53.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.9 MB 55.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 31.3 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.2\n",
      "    Uninstalling numpy-1.21.2:\n",
      "      Successfully uninstalled numpy-1.21.2\n",
      "Successfully installed numpy-2.0.2 pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cartopy 0.23.0 requires matplotlib>=3.5, which is not installed.\n",
      "pyogrio 0.9.0 requires certifi, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICON SIZE DEPENDING ON DISTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/1.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/2.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/3.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/4.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/5.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/6.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/7.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/8.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/9.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/10.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/11.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/12.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/13.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/14.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/15.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/16.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/17.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/18.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/19.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/20.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/21.asset\n",
      "Lua script generated and saved to C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/22.asset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "#import requests  # Import requests module for HTTP requests\n",
    "from urllib.parse import unquote\n",
    "\n",
    "# Configuration\n",
    "csv_file_path = 'C:/Users/alundkvi/Documents/work/data/auroraData/Filter_web_observation_may2024.csv'\n",
    "output_file_base = 'C:/Users/alundkvi/Documents/work/data/auroraData/assetOutput/aurorasaurusMay2024SizeSwitch/'\n",
    "image_base_path = 'C:/Users/alundkvi/Documents/work/data/auroraData/mayImagesCompressed/'\n",
    "user_assets_path = '${USER_ASSETS}/aurorasaurus/icons/newIcons2/'\n",
    "user_assets_path_shapes = '${USER_ASSETS}/aurorasaurus/icons/newIcons3/'\n",
    "not_seen_aurora_icon_path = '${USER_ASSETS}/aurorasaurus/icons/grayIcon.png'\n",
    "default_icon_path = 'green2.png'\n",
    "offset_step = 0.2  # Small offset step for adjusting positions\n",
    "distance_threshold = 0.2\n",
    "max_variables_per_file = 190  # Maximum number of local variables per file\n",
    "\n",
    "# Define image paths based on colors\n",
    "color_to_image_path = {\n",
    "    'green': 'green2.png',\n",
    "    'red': 'red2.png',\n",
    "    'white': 'white2.png',\n",
    "    'pink': 'pink2.png',\n",
    "    'green,red': 'greenRed2.png',\n",
    "    'green,white': 'greenWhite2.png',\n",
    "    'green,pink': 'greenPink2.png',\n",
    "    'green,red,white': 'greenRedWhite2.png',\n",
    "    'green,pink,red': 'greenRedPink2.png',\n",
    "    'green,pink,white': 'greenWhitePink2.png',\n",
    "    'green,pink,red,white': 'greenRedWhitePink2.png',\n",
    "    'red,white': 'redWhite2.png',\n",
    "    'pink,red': 'redPink2.png',\n",
    "    'pink,red,white': 'redWhitePink2.png',\n",
    "    'pink,white': 'whitePink2.png'\n",
    "}\n",
    "\n",
    "color_to_image_path_camera = {\n",
    "    'green': 'greenCamera.png',\n",
    "    'red': 'redCamera.png',\n",
    "    'white': 'whiteCamera.png',\n",
    "    'pink': 'pinkCamera.png',\n",
    "    'green,red': 'greenRedCamera.png',\n",
    "    'green,white': 'greenWhiteCamera.png',\n",
    "    'green,pink': 'greenPinkCamera.png',\n",
    "    'green,red,white': 'greenRedWhiteCamera.png',\n",
    "    'green,pink,red': 'greenRedPinkCamera.png',\n",
    "    'green,pink,white': 'greenWhitePinkCamera.png',\n",
    "    'green,pink,red,white': 'greenRedWhitePinkCamera.png',\n",
    "    'red,white': 'redWhiteCamera.png',\n",
    "    'pink,red': 'redPinkCamera.png',\n",
    "    'pink,red,white': 'redWhitePinkCamera.png',\n",
    "    'pink,white': 'whitePinkCamera.png'\n",
    "} \n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Ensure all_colors is a string and handle missing values\n",
    "df['all_colors'] = df['all_colors'].fillna('').astype(str)\n",
    "\n",
    "# Lua Template\n",
    "lua_template = '''local {var_name} = {{\n",
    "  Identifier = \"{identifier}\",\n",
    "  Parent = earth.Earth.Identifier,\n",
    "  TimeFrame = {{\n",
    "    Type = \"TimeFrameInterval\",\n",
    "    Start = \"{start_time}\",\n",
    "    End = \"{end_time}\"\n",
    "  }},\n",
    "  Transform = {{\n",
    "    Translation = {{\n",
    "      Type = \"GlobeTranslation\",\n",
    "      Globe = earth.Earth.Identifier,\n",
    "      Latitude = {latitude},\n",
    "      Longitude = {longitude},\n",
    "      Altitude = {altitude},\n",
    "      UseHeightmap = false\n",
    "    }}\n",
    "  }},\n",
    "  Renderable = {{\n",
    "    Type = \"{renderable_type}\",\n",
    "    {renderable_details}\n",
    "  }},\n",
    "  GUI = {{\n",
    "    Path = \"/{gui_path}\",\n",
    "    Name = \"{gui_name}\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "'''\n",
    "\n",
    "# Function to write Lua script to file (modified for appending)\n",
    "def write_lua_script(filename, lua_script, aurora_identifiers):\n",
    "    earth_asset_code = 'local earth = asset.require(\"scene/solarsystem/planets/earth/earth\")\\n\\n'\n",
    "\n",
    "    earth_asset = \"scene/solarsystem/planets/earth/earth\"\n",
    "    earth_asset_code = f'local earth = asset.require(\"{earth_asset}\")\\n\\n'\n",
    "\n",
    "    asset_management_code = \"\\n\\nasset.onInitialize(function()\\n\"\n",
    "    asset_management_code += ''.join([f\"  openspace.addSceneGraphNode({identifier})\\n\" for identifier in aurora_identifiers])\n",
    "    asset_management_code += \"end)\\n\\n\"\n",
    "\n",
    "    asset_management_code += \"asset.onDeinitialize(function()\\n\"\n",
    "    asset_management_code += ''.join([f\"  openspace.removeSceneGraphNode({identifier})\\n\" for identifier in aurora_identifiers])\n",
    "    asset_management_code += \"end)\\n\\n\"\n",
    "\n",
    "    asset_management_code += ''.join([f\"asset.export({identifier})\\n\" for identifier in aurora_identifiers])\n",
    "\n",
    "    final_lua_script = earth_asset_code + '\\n'.join(lua_script) + asset_management_code\n",
    "\n",
    "    # Append to file using 'a' mode to ensure appending\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(final_lua_script)\n",
    "\n",
    "    print(f\"Lua script generated and saved to {filename}\")\n",
    "\n",
    "# Function to generate Lua code\n",
    "def generate_lua_code(var_name, identifier, start_time, end_time, latitude, longitude, altitude, renderable_type, renderable_details, gui_path, gui_name):\n",
    "    return lua_template.format(\n",
    "        var_name=var_name,\n",
    "        identifier=identifier,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        latitude=latitude,\n",
    "        longitude=longitude,\n",
    "        altitude = altitude,\n",
    "        renderable_type=renderable_type,\n",
    "        renderable_details=renderable_details,\n",
    "        gui_path=gui_path,\n",
    "        gui_name=gui_name\n",
    "    )\n",
    "\n",
    "# Haversine formula to calculate the distance between two points\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Earth radius in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Function to adjust positions if they are within the distance threshold\n",
    "def adjust_position(existing_positions, latitude, longitude):\n",
    "    for (lat, lon) in existing_positions:\n",
    "        if haversine(lat, lon, latitude, longitude) < distance_threshold:\n",
    "            latitude += offset_step\n",
    "            longitude += offset_step\n",
    "    return latitude, longitude\n",
    "\n",
    "# Initialize lists and counters\n",
    "start_date = pd.Timestamp('2024-05-9').tz_localize(None)\n",
    "end_date = pd.Timestamp('2024-05-13').tz_localize(None)\n",
    "chunk_counter = 0\n",
    "lua_scripts = []\n",
    "aurora_identifiers = []\n",
    "\n",
    "# Loop through DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "  \n",
    "  time_start = pd.Timestamp(row['time_start']).tz_localize(None)\n",
    "  if start_date <= time_start <= end_date:\n",
    "      longitude, latitude = map(float, re.findall(r'[-]?\\d+\\.\\d+', row['location']))\n",
    "\n",
    "      # Adjust position if overlapping\n",
    "      #latitude, longitude = adjust_position(existing_positions, latitude, longitude)\n",
    "      #existing_positions.append((latitude, longitude))\n",
    "\n",
    "      start_time = time_start.strftime('%Y %b %d %H:%M:%S')\n",
    "      end_time = pd.to_datetime(row['time_end']).strftime('%Y %b %d %H:%M:%S')\n",
    "      if not row['see_aurora']:\n",
    "          #continue\n",
    "          var_name = f\"notSeenAuroraIcon{index+1}\"\n",
    "          identifier = var_name\n",
    "          icon_path = not_seen_aurora_icon_path\n",
    "          altitude = 95000\n",
    "          gui_name = f\"Aurora not seen {index+1}\"\n",
    "          renderable_details = f'''Size = 1,\n",
    "    Origin = \"Center\",\n",
    "    Billboard = true,\n",
    "    Texture = \"{icon_path}\",\n",
    "    Opacity = 1.0,\n",
    "    Enabled = true,\n",
    "    ScaleByDistance = true,\n",
    "    ScaleRatio = 0.01,\n",
    "    ScaleByDistanceMaxHeight = 200000,\n",
    "    RenderBinMode = \"PostDeferredTransparent\",\n",
    "    ScaleByDistanceMinHeight = 30000'''\n",
    "          renderable_type = \"RenderablePlaneImageLocal\"\n",
    "      else:\n",
    "          colors = [c.strip().lower() for c in row['all_colors'].split(',')]\n",
    "\n",
    "          # Join sorted colors to handle combinations correctly\n",
    "          color_key = ','.join(sorted(colors))\n",
    "\n",
    "          if not pd.isna(row['image']) and row['image'] != 'NA':\n",
    "              var_name = f\"Aurora{''.join([c.capitalize() for c in colors])}{index+1}\"\n",
    "              identifier = var_name\n",
    "              image_name = f\"image_{index+1}.{'jpg' if os.path.exists(os.path.join(image_base_path, f'image_{index+1}.jpg')) else 'png'}\"\n",
    "              icon_path = user_assets_path + color_to_image_path_camera.get(color_key, default_icon_path)\n",
    "              altitude = 120000\n",
    "              gui_name = f\"Aurora Image {index+1}\"\n",
    "              renderable_details = f'''Renderable1 = {{\n",
    "        Type = \"RenderablePlaneImageLocal\",\n",
    "        Size = 50000,\n",
    "        Origin = \"Center\",\n",
    "        Billboard = true,\n",
    "        Texture = \"{image_base_path}{image_name}\",\n",
    "        Opacity = 1,\n",
    "        Enabled = true\n",
    "      }},\n",
    "    Renderable2 = {{\n",
    "      Type = \"RenderablePlaneImageLocal\",\n",
    "      Size = 1,\n",
    "      Origin = \"Center\",\n",
    "      Billboard = true,\n",
    "      Texture = \"{icon_path}\",\n",
    "      Opacity = 1,\n",
    "      Enabled = true,\n",
    "      ScaleByDistance = true,\n",
    "      ScaleRatio = 0.01,\n",
    "      ScaleByDistanceMaxHeight = 200000,\n",
    "      ScaleByDistanceMinHeight = 30000\n",
    "    }},\n",
    "    RenderBinMode = \"PostDeferredTransparent\",\n",
    "    DistanceThreshold = 1000000'''\n",
    "              renderable_type = \"RenderableSwitch\"\n",
    "          else:\n",
    "              var_name = f\"icon{''.join([c.capitalize() for c in colors])}{index+1}\"\n",
    "              identifier = var_name\n",
    "              icon_path = user_assets_path + color_to_image_path.get(color_key, default_icon_path)\n",
    "              #icon_path2 = user_assets_path_shapes + color_to_image_path.get(color_key, default_icon_path)\n",
    "              gui_name = f\"Time Frame Icon {' '.join([c.capitalize() for c in colors])} {index+1}\"\n",
    "              altitude = 100000\n",
    "              renderable_details = f'''Size = 1,\n",
    "      Origin = \"Center\",\n",
    "      Billboard = true,\n",
    "      Texture = \"{icon_path}\",\n",
    "      Opacity = 1.0,\n",
    "      Enabled = true,\n",
    "      ScaleByDistance = true,\n",
    "      ScaleRatio = 0.01,\n",
    "      ScaleByDistanceMaxHeight = 200000,\n",
    "      RenderBinMode = \"PostDeferredTransparent\",\n",
    "      ScaleByDistanceMinHeight = 30000'''\n",
    "              renderable_type = \"RenderablePlaneImageLocal\"\n",
    "\n",
    "      # Generate Lua code and append to lua_scripts\n",
    "      lua_code = generate_lua_code(var_name, identifier, start_time, end_time, latitude, longitude, altitude, renderable_type, renderable_details.strip(), \"Aurorasaurus/IconsWithoutImage\" if row['image'] == 'NA' else \"Aurorasaurus\", gui_name)\n",
    "      lua_scripts.append(lua_code)\n",
    "      aurora_identifiers.append(identifier)\n",
    "\n",
    "      # Check if we need to write lua_scripts to a new file\n",
    "      if len(lua_scripts) >= max_variables_per_file:\n",
    "          chunk_counter += 1\n",
    "          filename = f\"{output_file_base}{chunk_counter}.asset\"\n",
    "          write_lua_script(filename, lua_scripts, aurora_identifiers)\n",
    "          # Reset lua_scripts and aurora_identifiers for the next chunk\n",
    "          lua_scripts = []\n",
    "          aurora_identifiers = []\n",
    "\n",
    "# Write remaining lua_scripts to file if any\n",
    "if lua_scripts:\n",
    "    chunk_counter += 1\n",
    "    filename = f\"{output_file_base}{chunk_counter}.asset\"\n",
    "    write_lua_script(filename, lua_scripts, aurora_identifiers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyOpenGLNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading PyOpenGL-3.1.7-py3-none-any.whl.metadata (3.2 kB)\n",
      "Downloading PyOpenGL-3.1.7-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 6.9 MB/s eta 0:00:00\n",
      "Installing collected packages: PyOpenGL\n",
      "Successfully installed PyOpenGL-3.1.7\n"
     ]
    }
   ],
   "source": [
    "%pip install PyOpenGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py\n",
      "  Downloading h5py-3.12.1-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages (from h5py) (2.0.2)\n",
      "Downloading h5py-3.12.1-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/3.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.6/3.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.6/3.0 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 5.2 MB/s eta 0:00:00\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-3.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data' is a group. Its contents are:\n",
      " - Dataset: grid\n",
      " - Group: source_info\n",
      " - Dataset: timestamp\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def read_h5_file(file_path, dataset_name):\n",
    "    with h5py.File(file_path, 'r') as h5_file:\n",
    "        # Check if the specified dataset or group exists\n",
    "        if dataset_name in h5_file:\n",
    "            item = h5_file[dataset_name]\n",
    "            if isinstance(item, h5py.Dataset):\n",
    "                # If it's a dataset, read it\n",
    "                data = item[:]\n",
    "                print(f\"Data from '{dataset_name}':\", data)\n",
    "            elif isinstance(item, h5py.Group):\n",
    "                # If it's a group, list its contents\n",
    "                print(f\"'{dataset_name}' is a group. Its contents are:\")\n",
    "                for sub_item_name in item:\n",
    "                    sub_item = item[sub_item_name]\n",
    "                    if isinstance(sub_item, h5py.Dataset):\n",
    "                        print(f\" - Dataset: {sub_item_name}\")\n",
    "                    else:\n",
    "                        print(f\" - Group: {sub_item_name}\")\n",
    "        else:\n",
    "            print(f\"Dataset or group '{dataset_name}' not found in the file.\")\n",
    "\n",
    "\n",
    "file_path = 'C:/Users/alundkvi/Downloads/mothers_day_storm_data_for_bea/mothers_day_storm_data_for_bea/grid_gillam/rgb/2024/05/11/ut07/20240511_0723_110km_MOSv001_grid_trex-rgb.h5'\n",
    "\n",
    "# Replace 'data' or 'metadata' with the name of the dataset you want to read\n",
    "dataset_name = 'data'  # Change this to 'metadata' if needed\n",
    "read_h5_file(file_path, dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'metadata' is a group. Its contents are:\n",
      " - Dataset: file: []\n",
      " - Group: frame\n",
      "'frame' is a group. Its contents are:\n",
      " - Dataset: frame0: []\n",
      " - Dataset: frame1: []\n",
      " - Dataset: frame10: []\n",
      " - Dataset: frame11: []\n",
      " - Dataset: frame12: []\n",
      " - Dataset: frame13: []\n",
      " - Dataset: frame14: []\n",
      " - Dataset: frame15: []\n",
      " - Dataset: frame16: []\n",
      " - Dataset: frame17: []\n",
      " - Dataset: frame18: []\n",
      " - Dataset: frame19: []\n",
      " - Dataset: frame2: []\n",
      " - Dataset: frame3: []\n",
      " - Dataset: frame4: []\n",
      " - Dataset: frame5: []\n",
      " - Dataset: frame6: []\n",
      " - Dataset: frame7: []\n",
      " - Dataset: frame8: []\n",
      " - Dataset: frame9: []\n",
      "'data' is a group. Its contents are:\n",
      " - Dataset: grid: [[[[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[ 127.  128.  130. ...  130.  129.  126.]\n",
      "   [ 152.  152.  153. ...  149.  150.  149.]\n",
      "   [ 167.  166.  167. ...  168.  170.  165.]]]\n",
      "\n",
      "\n",
      " [[[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]]\n",
      "\n",
      "\n",
      " [[[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]]\n",
      "\n",
      "\n",
      " [[[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]]\n",
      "\n",
      "\n",
      " [[[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]\n",
      "\n",
      "  [[-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]\n",
      "   [-999. -999. -999. ... -999. -999. -999.]]]]\n",
      " - Group: source_info\n",
      "'source_info' is a group. Its contents are:\n",
      " - Dataset: confidence: [[[-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  ...\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [  13.835754   13.835754   13.835754 ...   13.835754   13.835754\n",
      "     13.835754]]\n",
      "\n",
      " [[-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  ...\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]]\n",
      "\n",
      " [[-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  ...\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  ...\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]]\n",
      "\n",
      " [[-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  ...\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]]\n",
      "\n",
      " [[-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  ...\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]\n",
      "  [-999.       -999.       -999.       ... -999.       -999.\n",
      "   -999.      ]]]\n",
      " - Dataset: timestamp: [b'2024-05-11 07:23:00 UTC' b'2024-05-11 07:23:03 UTC'\n",
      " b'2024-05-11 07:23:06 UTC' b'2024-05-11 07:23:09 UTC'\n",
      " b'2024-05-11 07:23:12 UTC' b'2024-05-11 07:23:15 UTC'\n",
      " b'2024-05-11 07:23:18 UTC' b'2024-05-11 07:23:21 UTC'\n",
      " b'2024-05-11 07:23:24 UTC' b'2024-05-11 07:23:27 UTC'\n",
      " b'2024-05-11 07:23:30 UTC' b'2024-05-11 07:23:33 UTC'\n",
      " b'2024-05-11 07:23:36 UTC' b'2024-05-11 07:23:39 UTC'\n",
      " b'2024-05-11 07:23:42 UTC' b'2024-05-11 07:23:45 UTC'\n",
      " b'2024-05-11 07:23:48 UTC' b'2024-05-11 07:23:51 UTC'\n",
      " b'2024-05-11 07:23:54 UTC' b'2024-05-11 07:23:57 UTC']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def print_group_contents(group, group_name):\n",
    "    print(f\"'{group_name}' is a group. Its contents are:\")\n",
    "    for item_name in group:\n",
    "        item = group[item_name]\n",
    "        if isinstance(item, h5py.Dataset):\n",
    "            print(f\" - Dataset: {item_name}: {item[:]}\")\n",
    "        elif isinstance(item, h5py.Group):\n",
    "            print(f\" - Group: {item_name}\")\n",
    "            print_group_contents(item, item_name)  # Recursively print contents of the subgroup\n",
    "\n",
    "def read_h5_file(file_path):\n",
    "    with h5py.File(file_path, 'r') as h5_file:\n",
    "        # List and print contents of 'metadata'\n",
    "        if 'metadata' in h5_file:\n",
    "            metadata_group = h5_file['metadata']\n",
    "            print_group_contents(metadata_group, 'metadata')\n",
    "\n",
    "        # List and print contents of 'data'\n",
    "        if 'data' in h5_file:\n",
    "            data_group = h5_file['data']\n",
    "            print_group_contents(data_group, 'data')\n",
    "\n",
    "file_path = 'C:/Users/alundkvi/Downloads/mothers_day_storm_data_for_bea/mothers_day_storm_data_for_bea/grid_gillam/rgb/2024/05/11/ut07/20240511_0723_110km_MOSv001_grid_trex-rgb.h5'\n",
    "read_h5_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages (2.0.2)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.54.1-cp39-cp39-win_amd64.whl.metadata (167 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-10.4.0-cp39-cp39-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.2-cp39-cp39-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/7.8 MB 1.7 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.3/7.8 MB 2.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.8/7.8 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.4/7.8 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 3.4/7.8 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 4.5/7.8 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 5.8/7.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.3/7.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.8/7.8 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.54.1-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 1.8/2.2 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading kiwisolver-1.4.7-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Downloading pillow-10.4.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 2.4/2.6 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-10.4.0 pyparsing-3.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'c:\\Users\\alundkvi\\micromamba\\envs\\foo\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1024, 3, 20) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m     25\u001b[0m \u001b[39m# Use imshow to display the grid data\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m plt\u001b[39m.\u001b[39;49mimshow(grid, cmap\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mviridis\u001b[39;49m\u001b[39m'\u001b[39;49m, interpolation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnearest\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     27\u001b[0m plt\u001b[39m.\u001b[39mcolorbar(label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValue\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Optional: add colorbar\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m# Format the timestamp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages\\matplotlib\\pyplot.py:3562\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   3541\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mimshow)\n\u001b[0;32m   3542\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow\u001b[39m(\n\u001b[0;32m   3543\u001b[0m     X: ArrayLike \u001b[39m|\u001b[39m PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mImage,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3560\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3561\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AxesImage:\n\u001b[1;32m-> 3562\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39mimshow(\n\u001b[0;32m   3563\u001b[0m         X,\n\u001b[0;32m   3564\u001b[0m         cmap\u001b[39m=\u001b[39mcmap,\n\u001b[0;32m   3565\u001b[0m         norm\u001b[39m=\u001b[39mnorm,\n\u001b[0;32m   3566\u001b[0m         aspect\u001b[39m=\u001b[39maspect,\n\u001b[0;32m   3567\u001b[0m         interpolation\u001b[39m=\u001b[39minterpolation,\n\u001b[0;32m   3568\u001b[0m         alpha\u001b[39m=\u001b[39malpha,\n\u001b[0;32m   3569\u001b[0m         vmin\u001b[39m=\u001b[39mvmin,\n\u001b[0;32m   3570\u001b[0m         vmax\u001b[39m=\u001b[39mvmax,\n\u001b[0;32m   3571\u001b[0m         origin\u001b[39m=\u001b[39morigin,\n\u001b[0;32m   3572\u001b[0m         extent\u001b[39m=\u001b[39mextent,\n\u001b[0;32m   3573\u001b[0m         interpolation_stage\u001b[39m=\u001b[39minterpolation_stage,\n\u001b[0;32m   3574\u001b[0m         filternorm\u001b[39m=\u001b[39mfilternorm,\n\u001b[0;32m   3575\u001b[0m         filterrad\u001b[39m=\u001b[39mfilterrad,\n\u001b[0;32m   3576\u001b[0m         resample\u001b[39m=\u001b[39mresample,\n\u001b[0;32m   3577\u001b[0m         url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   3578\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}),\n\u001b[0;32m   3579\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3580\u001b[0m     )\n\u001b[0;32m   3581\u001b[0m     sci(__ret)\n\u001b[0;32m   3582\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mc:\\Users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages\\matplotlib\\__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1471\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1472\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1473\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\n\u001b[0;32m   1474\u001b[0m             ax,\n\u001b[0;32m   1475\u001b[0m             \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args),\n\u001b[0;32m   1476\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: sanitize_sequence(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()})\n\u001b[0;32m   1478\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1479\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1480\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5895\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5892\u001b[0m \u001b[39mif\u001b[39;00m aspect \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5893\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m-> 5895\u001b[0m im\u001b[39m.\u001b[39;49mset_data(X)\n\u001b[0;32m   5896\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5897\u001b[0m \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5898\u001b[0m     \u001b[39m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages\\matplotlib\\image.py:729\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(A, PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mImage):\n\u001b[0;32m    728\u001b[0m     A \u001b[39m=\u001b[39m pil_to_array(A)  \u001b[39m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[1;32m--> 729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_normalize_image_array(A)\n\u001b[0;32m    730\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_imcache \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    731\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alundkvi\\micromamba\\envs\\foo\\lib\\site-packages\\matplotlib\\image.py:697\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m    695\u001b[0m     A \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]):\n\u001b[1;32m--> 697\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid shape \u001b[39m\u001b[39m{\u001b[39;00mA\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m for image data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    698\u001b[0m \u001b[39mif\u001b[39;00m A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m    699\u001b[0m     \u001b[39m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[39m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[0;32m    701\u001b[0m     \u001b[39m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[0;32m    702\u001b[0m     \u001b[39m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     high \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(A\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger) \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (1024, 3, 20) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = 'C:/Users/alundkvi/Downloads/mothers_day_storm_data_for_bea/mothers_day_storm_data_for_bea/grid_gillam/rgb/2024/05/11/ut07/20240511_0723_110km_MOSv001_grid_trex-rgb.h5'\n",
    "\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    grid_data = f['data/grid'][:]  # Adjust this path as needed\n",
    "    \n",
    "    # Access the timestamps\n",
    "    timestamps = f['data/timestamp'][:]  # Adjust this path as needed\n",
    "\n",
    "    for i in range(grid_data.shape[0]):  # Iterate through frames\n",
    "        grid = grid_data[i]\n",
    "        \n",
    "        # If grid has shape (1024, 3, 20), select one channel or average\n",
    "        # Option 1: Select the first channel\n",
    "        # grid = grid[:, 0, :]  # Use this if you want to visualize one channel\n",
    "\n",
    "        # Option 2: Average across the channels (if they are similar)\n",
    "        grid = np.mean(grid, axis=1)  # Average over the second dimension\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(grid, cmap='viridis', interpolation='nearest')\n",
    "        plt.colorbar(label='Value')  # Optional: add colorbar\n",
    "        \n",
    "        # Format the timestamp (adjust based on your data type)\n",
    "        timestamp_str = str(timestamps[i])  # Convert timestamp to string if needed\n",
    "        plt.title(f'Aurora Image for Timestamp: {timestamp_str}')\n",
    "        \n",
    "        # Save the image or display it\n",
    "        plt.savefig(f'aurora_image_{i}.png')  # Save as PNG\n",
    "        plt.show()  # Or just show the image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
